{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "## 一. 数据标准化,去均值,方差缩放\n",
    "### 1. 样本点去均值,标准差缩放  \n",
    "准备数据点\n",
    "```python\n",
    ">>> from sklearn import preprocessing\n",
    ">>> import numpy as np\n",
    ">>> X = np.array([[ 1., -1.,  2.],[ 2.,  0.,  0.],[ 0.,  1., -1.]])\n",
    ">>> X\n",
    "array([[ 1., -1.,  2.],\n",
    "       [ 2.,  0.,  0.],\n",
    "       [ 0.,  1., -1.]])\n",
    "```\n",
    "( 1 ) 声明StandardScaler  \n",
    "也可以通过在构造函数:class:StandardScaler`中传入参数``with_mean=False` 或者``with_std=False``来取消中心化或缩放操作\n",
    "```python\n",
    ">>> scaler = preprocessing.StandardScaler().fit(X)\n",
    ">>> scaler\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "```\n",
    "( 2 ) 显示样本均值,标准差  \n",
    "```python\n",
    ">>> scaler.mean_  \n",
    "array([ 1.        ,  0.        ,  0.33333333])\n",
    ">>> scaler.scale_ \n",
    "array([ 0.81649658,  0.81649658,  1.24721913])\n",
    "```\n",
    "( 3 ) 转换训练集\n",
    "```python\n",
    ">>> X_scale = scaler.transform(X)\n",
    ">>> X_scale\n",
    "array([[ 0.        , -1.22474487,  1.33630621],\n",
    "       [ 1.22474487,  0.        , -0.26726124],\n",
    "       [-1.22474487,  1.22474487, -1.06904497]])\n",
    "```\n",
    "( 4 ) 用scaler缩放新数据\n",
    "```python\n",
    ">>> scaler.transform([[-1,1,0]])\n",
    "array([[-2.44948974,  1.22474487, -0.26726124]])\n",
    "```\n",
    "\n",
    "### 2. MinMaxScaler缩放到[0,1]\n",
    "( 1 ) 缩放$X=\\frac { X-{ X }_{ min } }{ { X }_{ max }-{ X }_{ min } }$ \n",
    "```python\n",
    ">>> X\n",
    "array([[ 1., -1.,  2.],\n",
    "       [ 2.,  0.,  0.],\n",
    "       [ 0.,  1., -1.]])\n",
    ">>> min_max_scaler = preprocessing.MinMaxScaler()\n",
    ">>> X_scale = min_max_scaler.fit_transform(X_train)\n",
    ">>> X_scale\n",
    "array([[ 0.5       ,  0.        ,  1.        ],\n",
    "       [ 1.        ,  0.5       ,  0.33333333],\n",
    "       [ 0.        ,  1.        ,  0.        ]])\n",
    "```\n",
    "\n",
    "### 3. MaxAbsScaler缩放到[-1,1]  \n",
    "( 1 ) 缩放特征 $X=\\frac { X }{ { |X| }_{ max } } $\n",
    "```python\n",
    ">>> X\n",
    "array([[ 1., -1.,  2.],\n",
    "       [ 2.,  0.,  0.],\n",
    "       [ 0.,  1., -1.]])\n",
    ">>> max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    ">>> X_train_maxabs = max_abs_scaler.fit_transform(X_train)\n",
    ">>> X_train_maxabs\n",
    "array([[ 0.5, -1. ,  1. ],\n",
    "       [ 1. ,  0. ,  0. ],\n",
    "       [ 0. ,  1. , -0.5]])\n",
    "```\n",
    "\n",
    "## 二.含异常值的数据缩放\n",
    "1. 如果数据包含较多的异常值，使用均值和方差缩放并不是一个很好的选择。在这种情况下，可以使用 robust_scale 和:class:RobustScaler 作为替代。它们使用更加鲁棒的中心和范围估计来缩放你的数据。  \n",
    "Further discussion on the importance of centering and scaling data is available on this FAQ: [Should I normalize/standardize/rescale the data?](http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html)  \n",
    "2. 有时因为一些下层的学习算法需要特征之间是线性独立的,所以单纯中心化和缩放数据并不是足够的，为了解决这个问题，你可以使用:`class:sklearn.decomposition.PCA` 或者:`class:sklearn.decomposition.RandomizedPCA` 带参数``whiten=True``来进一步移除特征之间的线性相关性。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
