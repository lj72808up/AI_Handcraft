{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 生成模型\n",
    "\n",
    "#### 1. 生成算法与判别算法\n",
    "* 判别算法  \n",
    "  模型直接学习一个假设函数或直接对$p(y|x)$的概率建模, 进行极大似然估计  \n",
    "* 生成算法  \n",
    "  分别建立2个概率模型$p\\left( y \\right)$与$p\\left( x|y \\right) $, 在用贝叶斯后验概率作为预测值.  \n",
    "  \n",
    "#### 2. 高斯判别  \n",
    "高斯判别假设训练集的标签集合{y}服从伯努利分布.假设$p(x|y)$服从多元高斯分布, 作如下统计:  \n",
    "$$\\begin{cases} \\phi =p(y=1)=\\frac { 1 }{ m } \\sum _{  }^{ m }{ I({ y }^{ i }=1) }  \\\\ { \\mu  }_{ 0 }=\\frac { \\sum _{  }^{ m }{ I({ y }^{ i }=0){ x }^{ i } }  }{ \\sum _{  }^{ m }{ I({ y }^{ i }=0) }  }  \\\\ { \\mu  }_{ 1 }=\\frac { \\sum _{  }^{ m }{ I({ y }^{ i }=1){ x }^{ i } }  }{ \\sum _{  }^{ m }{ I({ y }^{ i }=1) }  }  \\\\ \\Sigma =\\frac { 1 }{ m } \\sum _{  }^{ m }{ \\left( { x }^{ i }-{ \\mu  }_{ { y }^{ i } } \\right) { \\left( { x }^{ i }-{ \\mu  }_{ { y }^{ i } } \\right)  }^{ T } }  \\end{cases}$$ \n",
    "此后, 预测新样本的概率 $$p\\left( y=1|x \\right) =\\frac { p\\left( x|y=1 \\right) P(y=1) }{ p\\left( x \\right)  } ,带入 p\\left( x \\right) =p\\left( x|y=1 \\right) P(y=1)+p\\left( x|y=0 \\right) P(y=0)$$\n",
    "\n",
    "#### 3. 高斯判别与逻辑回归  \n",
    "1. 高斯判别假设x服从多元高斯分布,标签集服从伯努利分布. 所以在特征确实服从高斯分布的情况下, 其效果会稍好于逻辑回归  \n",
    "2. 因为高斯判别做了更强的假设, 所以高斯判别在数据不足的情况下表现效果更好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 朴素贝叶斯\n",
    "\n",
    "#### 1.  朴素贝叶斯的预测过程  \n",
    "朴素贝叶斯也是生成模型, 利用贝叶斯后验概率做预测, 并假设特征之间是独立的, 这在如下公式推到中有所体现  \n",
    "给定新样本, 预测后验概率$$p\\left( y=1|x \\right) =\\frac { p\\left( x|y=1 \\right) P(y=1) }{ p\\left( x \\right)  } \\\\ \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad =\\frac { p\\left( x|y=1 \\right) P(y=1) }{ p\\left( x|y=1 \\right) P(y=1)+p\\left( x|y=0 \\right) P(y=0) } $$\n",
    "朴素贝叶斯, 假定特征之间独立, 就有$$p\\left( x|y=1 \\right) =\\prod _{ i=1 }^{ n }{ p\\left( { x }_{ i }|y=1 \\right)  } ,\\quad p\\left( x|y=0 \\right) =\\prod _{ i=1 }^{ n }{ p\\left( { x }_{ i }|y=0 \\right)  } $$\n",
    "因此, 朴素贝叶斯只需要从训练集中学习几个统计量:   \n",
    "$\\begin{cases} p\\left( { x }_{ i }|y=1 \\right)  \\\\ p\\left( { x }_{ i }|y=0 \\right)  \\\\ P(y=1) \\\\ P(y=0) \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 为什么朴素贝叶斯只能学习categorical型变量  \n",
    "从朴素贝叶斯的统计模型上看, 4个统计量要求${ x }_{ i }$只能取有限个值, 即\"类型特征\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 为什么使用拉普拉斯顺滑  \n",
    "因为统计量$p\\left( { x }_{ i }={ X }_{ i }|y=1 \\right) $只能学习到训练样本中出现的特征取值, 如果预测样本的特好着呢个取值在训练集中没有, 则会有$p({ x }_{ i }|y=1)=0$,   \n",
    "使得预测时的后验概率分子为0, 最终结果为0.   \n",
    "为解决这个问题, 拉普拉斯顺滑在预测时, 使用如下式子表示$p\\left( { x }_{ i }={ X }_{ i }|y=1 \\right) $:  \n",
    "$$p\\left( { x }_{ i }={ X }_{ i }|y=1 \\right) =\\frac { \\sum _{  }^{ m }{ I({ x }_{ i }={ X }_{ i };y=1) } +1 }{ \\sum _{  }^{ m }{ I(y=1) } +k } , k为特征{ x }_{ i }的取值个数$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
