{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 挖掘数据定义  \n",
    "遍历每一列, 阅读没类的描述确保理解这些数据表示的侧面, 并使用统计和绘图遍历列  \n",
    "可以查看其它data scientist的工作来理解每一列\n",
    "#### 2. 选择一个metric\n",
    "#### 3. Data Exploration and Data Cleaning  \n",
    "1. 此阶段要处理异常值和缺失值, 之后才能建模  \n",
    "2. 先查看数据标签的分布, 看数据是否平衡  \n",
    "   如果变迁季度不平衡, 就要注意在交叉验证时使用分层抽样  \n",
    "3. 不同的数据类型表示不同的统计类型  \n",
    "    1. float可能是连续值  \n",
    "    2. int可能是boolean型或离散的有序变量    \n",
    "       可通过查看int型列的值个数确定; train.select_dtypes('object').count_values()\n",
    "    3. object/categorical可能是标签  \n",
    "       train.select_dtypes('object').head()\n",
    "4. 缺失值处理  \n",
    "   计算每一列缺失值比例  \n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    # Number of missing in each column\n",
    "    missing = pd.DataFrame(data.isnull().sum()).rename(columns = {0: 'total'})\n",
    "    # Create a percentage missing\n",
    "    missing['percent'] = missing['total'] / len(data) \n",
    "    ```\n",
    "    \n",
    "#### 4. Feature Engineering  \n",
    "分为手动特征工程和自动特征工程(featuretools,十分之一的时间却有更好的效果)\n",
    "手动特征工程:  \n",
    "1. 首先, 根据id查看每一列的统计属性   \n",
    "```python\n",
    "# Aggregate individual data for each household\n",
    "id_agg = ind.groupby('id').agg(['min', 'max', 'mean', 'sum'])  \n",
    "这会多出来4倍的统计属性, 而且多数存在线性相关性 , 因此需要做特征选择  \n",
    "```\n",
    "2. 其次, 可以利用领域知识构建新特征  \n",
    "```python\n",
    "# No toilet, no electricity, no floor, no water service, no ceiling\n",
    "house['warning'] = 1 * (house['sanitario1'] + \n",
    "                        (house['elec'] == 0) + \n",
    "                        house['pisonotiene'] + \n",
    "                        house['abastaguano'] + \n",
    "                        (house['cielorazo'] == 0))\n",
    "```  \n",
    "最好的方法是手动增加新特征后,再使用feature tools进行自动特征\n",
    "\n",
    "#### 5. Feature Selection  \n",
    "一种方法是查看两个特征之间的相关性, 相关系数高的叫做高线性相关\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "threshold = 0.95\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_matrix = data.corr()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(abs(upper[column]) > threshold)]\n",
    "\n",
    "data = data.drop(columns = to_drop)\n",
    "\n",
    "还可以通过模型, 如随机森林来选择特征\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
